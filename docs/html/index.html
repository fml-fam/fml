<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>fml: fml</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="fml_small.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">fml
   &#160;<span id="projectnumber">0.1-0</span>
   </div>
   <div id="projectbrief">Fused Matrix Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('index.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">fml </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li><b>Version:</b> 0.1-0</li>
<li><b>License:</b> <a href="http://opensource.org/licenses/BSL-1.0">BSL-1.0</a></li>
<li><b>Project home</b>: <a href="https://github.com/wrathematics/fml">https://github.com/wrathematics/fml</a></li>
<li><b>Bug reports</b>: <a href="https://github.com/wrathematics/fml/issues">https://github.com/wrathematics/fml/issues</a></li>
<li><b>Documentation</b>: TODO</li>
</ul>
<div class="image">
<img src="./docs/logo/fml_med.png" align="right"/>
</div>
<p>fml is the Fused Matrix Library, a multi-source, header-only C++ library for dense matrix computing. The emphasis is on real-valued matrix types (<code>float</code>, <code>double</code>, and <code>__half</code>) for numerical operations useful for data analysis.</p>
<p>The goal of fml is to be "medium-level". That is, high-level compared to working directly with e.g. the BLAS or CUDA™, but low(er)-level compared to other C++ matrix frameworks. Some knowledge of the use of LAPACK will make many choices in fml make more sense.</p>
<p>The library provides 4 main classes: <code>cpumat</code>, <code>gpumat</code>, <code>parmat</code>, and <code>mpimat</code>. These are mostly what they sound like, but the particular details are:</p>
<ul>
<li>&lt;font color="blue"&gt;CPU&lt;/font&gt;: Single node cpu computing (multi-threaded if using multi-threaded BLAS and linking with OpenMP).</li>
<li>&lt;font color="green"&gt;GPU&lt;/font&gt;: Single gpu computing.</li>
<li>&lt;font color="red"&gt;MPI&lt;/font&gt;: Multi-node computing via ScaLAPACK (+gpus if using <a href="http://icl.utk.edu/slate/">SLATE</a>).</li>
<li>&lt;font color="orange"&gt;PAR&lt;/font&gt;: Multi-node and/or multi-gpu computing.</li>
</ul>
<p>There are some differences in how objects of any particular type are constructed. But the high level APIs are largely the same between the objects. The goal is to be able to quickly create laptop-scale prototypes that are then easily converted into large scale gpu/multi-node/multi-gpu/multi-node+multi-gpu codes.</p>
<h2>Installation</h2>
<p>The library is header-only so no installation is strictly necessary. You can just include a copy/submodule in your project. However, if you want some analogue of <code>make install</code>, then you could do something like:</p>
<div class="fragment"><div class="line">ln -s ./src /usr/include/fml</div></div><!-- fragment --><h2>Dependencies and Other Software</h2>
<p>There are no external header dependencies, but there are some shared libraries you need to have (more information below):</p>
<ul>
<li>CPU code needs <a href="http://performance.netlib.org/lapack/">LAPACK</a> (I recommend <a href="https://github.com/xianyi/OpenBLAS">OpenBLAS</a>)</li>
<li>GPU code needs <a href="https://developer.nvidia.com/cuda-downloads">NVIDIA® CUDA™</a></li>
<li>MPI code needs <a href="http://performance.netlib.org/scalapack/">ScaLAPACK</a></li>
<li>PAR code needs the libraries required by the CPU and/or GPU features, noted above.</li>
</ul>
<p>Other software we use:</p>
<ul>
<li>Tests use <a href="https://github.com/catchorg/Catch2">catch2</a> (a copy of which is included under <code>tests/</code>).</li>
</ul>
<p>You can find some examples of how to use the library in the <code>examples/</code> tree. Right now there is no real build system beyond some ad hoc makefiles; but ad hoc is better than no hoc.</p>
<p>Depending on which class(es) you want to use, here are some general guidelines for using the library in your own project:</p>
<ul>
<li>CPU: <code>cpumat</code><ul>
<li>Compile with your favorite C++ compiler.</li>
<li>Link with LAPACK and BLAS (and ideally with OpenMP).</li>
</ul>
</li>
<li>GPU: <code>gpumat</code><ul>
<li>Compile with <code>nvcc</code>.</li>
<li>For most functionality, link with libcudart, libcublas, and libcusolver. Link with libcurand if using the random generators. Link with libnvidia-ml if using nvml (if you're only using this, then you don't need <code>nvcc</code>; an ordinary C++ compiler will do). If you have CUDA installed and do not know what to link with, there is no harm in linking with all of these.</li>
</ul>
</li>
<li>MPI: <code>mpimat</code><ul>
<li>Compile with <code>mpicxx</code>.</li>
<li>Link with libscalapack.</li>
</ul>
</li>
<li>PAR: <code>parmat</code><ul>
<li>Compile with <code>mpicxx</code>.</li>
<li>Link with CPU stuff if using <code><a class="el" href="classparmat__cpu.html">parmat_cpu</a></code>; link with GPU stuff if using <code><a class="el" href="classparmat__gpu.html">parmat_gpu</a></code> (you can use both).</li>
</ul>
</li>
</ul>
<p>Check the makefiles in the <code>examples/</code> tree if none of that makes sense.</p>
<h2>High-Level Language Bindings</h2>
<ul>
<li>R bindings: <a href="https://github.com/wrathematics/fmlr">fmlr</a></li>
</ul>
<h2>API Stability</h2>
<p>The project is young and things are still mostly evolving. The current status is:</p>
<ul>
<li>Frozen - Existing APIs will not be developed further.<ul>
<li>none</li>
</ul>
</li>
<li>Stable - Existing APIs are not expected to change. Some new features may be added slowly.<ul>
<li>none</li>
</ul>
</li>
<li>Stabilizing - Core class naming and construction/destruction is probably finalized. Function/method names and arguments are solidifying, but may change somewhat. New features are still being developed.<ul>
<li>cpumat/gpumat/mpimat classes</li>
<li>cpuhelpers namespace functions</li>
<li>gpuhelpers namespace functions</li>
<li>linalg namespace (all but parmat)</li>
</ul>
</li>
<li>Evolving - Function/method names and arguments are subject to change. New features are actively being developed.<ul>
<li>mpihelpers namespace functions</li>
</ul>
</li>
<li>Experimental - Nothing is remotely finalized.<ul>
<li>parmat - all functions and methods</li>
</ul>
</li>
</ul>
<p>Internals are evolving and subject to change at basically any time.</p>
<h2>Example</h2>
<p>Here's a simple example computing the SVD with some data held on a single CPU:</p>
<div class="fragment"><div class="line">{C++}</div><div class="line">#include &lt;cpu/cpumat.hh&gt;</div><div class="line">#include &lt;cpu/linalg.hh&gt;</div><div class="line"></div><div class="line"></div><div class="line">int main()</div><div class="line">{</div><div class="line">  len_t m = 3;</div><div class="line">  len_t n = 2;</div><div class="line"></div><div class="line">  cpumat&lt;float&gt; x(m, n);</div><div class="line">  x.fill_linspace(1.f, (float)m*n);</div><div class="line"></div><div class="line">  x.info();</div><div class="line">  x.print(0);</div><div class="line"></div><div class="line">  cpuvec&lt;float&gt; s;</div><div class="line">  linalg::svd(x, s);</div><div class="line"></div><div class="line">  s.info();</div><div class="line">  s.print();</div><div class="line"></div><div class="line">  return 0;</div><div class="line">}</div></div><!-- fragment --><p>Save as <code>svd.cpp</code> and build with:</p>
<div class="fragment"><div class="line">g++ -I/path/to/fml/src -fopenmp svd.cpp -o svd -llapack -lblas</div></div><!-- fragment --><p>You should see output like</p>
<div class="fragment"><div class="line"># cpumat 3x2 type=f</div><div class="line">1 4 </div><div class="line">2 5 </div><div class="line">3 6 </div><div class="line"></div><div class="line"># cpuvec 2 type=f</div><div class="line">9.5080 0.7729 </div></div><!-- fragment --><p>The API is largely the same if we change the object storage, but we have to change the object initialization. For example, if <code>x</code> is an object of class <code>mpimat</code>, we still call <code>linalg::svd(x, s)</code>. The differences lie in the creation of the objects. Here is how we might change the above example to use distributed data:</p>
<div class="fragment"><div class="line">{C++}</div><div class="line">#include &lt;mpi/mpimat.hh&gt;</div><div class="line">#include &lt;mpi/linalg.hh&gt;</div><div class="line"></div><div class="line"></div><div class="line">int main()</div><div class="line">{</div><div class="line">  grid g = grid(PROC_GRID_SQUARE);</div><div class="line">  g.info();</div><div class="line"></div><div class="line">  len_t m = 3;</div><div class="line">  len_t n = 2;</div><div class="line"></div><div class="line">  mpimat&lt;float&gt; x(g, m, n, 1, 1);</div><div class="line">  x.fill_linspace(1.f, (float)m*n);</div><div class="line"></div><div class="line">  x.info();</div><div class="line">  x.print(0);</div><div class="line"></div><div class="line">  cpuvec&lt;float&gt; s;</div><div class="line">  linalg::svd(x, s);</div><div class="line"></div><div class="line">  if (g.rank0())</div><div class="line">  {</div><div class="line">    s.info();</div><div class="line">    s.print();</div><div class="line">  }</div><div class="line"></div><div class="line">  g.exit();</div><div class="line">  g.finalize();</div><div class="line"></div><div class="line">  return 0;</div><div class="line">}</div></div><!-- fragment --><p>In practice, using such small block sizes for an MPI matrix is probably not a good idea; we only do so for the sake of demonstration (we want each process to own some data). We can build this new example via:</p>
<div class="fragment"><div class="line">mpicxx -I/path/to/fml/src svd.cpp -fopenmp  svd.cpp -o svd -lscalapack-openmpi</div></div><!-- fragment --><p>We can launch the example with multiple processes via</p>
<div class="fragment"><div class="line">mpirun -np 4 ./svd</div></div><!-- fragment --><p>And here we see:</p>
<div class="fragment"><div class="line">## Grid 0 2x2</div><div class="line"></div><div class="line"># mpimat 3x2 on 2x2 grid type=f</div><div class="line">1 4 </div><div class="line">2 5 </div><div class="line">3 6 </div><div class="line"></div><div class="line"># cpuvec 2 type=f</div><div class="line">9.5080 0.7729 </div></div><!-- fragment --><h2>Philosophy and Similar Projects</h2>
<p>Some similar C/C++ projects worth mentioning:</p>
<ul>
<li><a href="http://arma.sourceforge.net/">Armadillo</a></li>
<li><a href="http://eigen.tuxfamily.org/">Eigen</a></li>
<li><a href="http://www.boost.org/">Boost</a></li>
<li><a href="https://www.mcs.anl.gov/petsc/">PETSc</a></li>
<li><a href="https://www.gnu.org/software/gsl/">GSL</a></li>
</ul>
<p>These are all great libraries which have stood the test of time. Armadillo in particular is worthy of a look, as it has a very nice interface and very extensive set of functions. However, to my knowledge, all of these focus exclusively on CPU computing. There are some extensions to Armadillo and Eigen for GPU computing. And for gemm-heavy codes, you can use <a href="https://docs.nvidia.com/cuda/nvblas/index.html">nvblas</a> to offload some work to the GPU, but this doesn't always achieve good performance. And none of the above include distributed computing, except for PETSc which focuses on sparse matrices.</p>
<p>There are probably many other C++ frameworks in this arena, but none to my knowledge have a similar scope to fml.</p>
<p>Probably the biggest influence on my thinking for this library is the <a href="https://github.com/RBigData">pbdR package ecosystem</a> for HPC with the R language, which I have worked on for many years now. Some obvious parallels are:</p>
<ul>
<li><a href="https://github.com/wrathematics/float">float</a> - CPU/GPU</li>
<li><a href="https://github.com/RBigData/kazaam">kazaam</a> - PAR</li>
<li><a href="https://github.com/RBigData/pbdDMAT">pbdDMAT</a> - MPI</li>
</ul>
<p>The basic philosophy of fml is:</p>
<ul>
<li>Be relatively small and self-contained.</li>
<li>Follow general C++ conventions by default (like RAII and exceptions), but give the ability to break these for the sake of performance.</li>
<li>Changing a code from one object type to another should be very simple, ideally with no changes to the source (the internals will simply <b>Do The Right Thing (tm)</b>), with the exception of:<ul>
<li>object creation</li>
<li>printing (e.g. printing on only one MPI rank)</li>
</ul>
</li>
<li>Use a permissive open source license. </li>
</ul>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
